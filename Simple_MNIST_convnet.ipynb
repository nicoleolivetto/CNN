{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0V9CowCJlVDKI4B4HZhq4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicoleolivetto/CNN/blob/main/Simple_MNIST_convnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "erXiZGFeJ1xW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-Define model and data parameters: It sets the number of classes (10 for the digits 0-9) and the input shape for the images (28x28 pixels with a single color channel).\n",
        "\n",
        "-Load and preprocess the MNIST dataset: It loads the MNIST dataset, which consists of a training set and a test set of 28x28 grayscale images of handwritten digits and their corresponding labels. The images are scaled to the range [0, 1] and expanded to have a shape of (28, 28, 1).\n",
        "\n",
        "-Convert labels to one-hot encoding: It converts the class labels to one-hot encoded vectors using keras.utils.to_categorical."
      ],
      "metadata": {
        "id": "gdH-Joi3sjfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# Load the data and split it between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jk0b7aqtJ7jf",
        "outputId": "0e7be4b4-8069-4c9e-e92e-688dddfc95b2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-Define the neural network model: The model is defined as a sequential neural network with the following layers:\n",
        "\n",
        "-Input layer: It takes the input shape.\n",
        "Convolutional layer with 32 filters, each with a 3x3 kernel and ReLU activation.\n",
        "Max-pooling layer with a 2x2 pool size.\n",
        "Another convolutional layer with 64 filters and a 3x3 kernel, followed by ReLU activation.\n",
        "Another max-pooling layer with a 2x2 pool size.\n",
        "A flatten layer to transform the 2D feature maps into a 1D vector.\n",
        "A dropout layer with a 50% dropout rate to prevent overfitting.\n",
        "A dense layer with 10 units and softmax activation for class prediction.\n",
        "Model summary: It prints a summary of the model architecture."
      ],
      "metadata": {
        "id": "Wpt3aZMBtS-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(7, 7), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0,5),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hlxt3yVKH_G",
        "outputId": "292abed7-fd1d-4149-e71a-25680b56e02f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 22, 22, 16)        800       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 11, 11, 16)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 9, 9, 64)          9280      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 4, 4, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20330 (79.41 KB)\n",
            "Trainable params: 20330 (79.41 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-Set training parameters: It defines the batch size (128) and the number of training epochs (15).\n",
        "\n",
        "-Compile the model: The model is compiled with the categorical cross-entropy loss function, the Adam optimizer, and accuracy as the metric.\n",
        "\n",
        "-Train the model: The model is trained using the training data. It splits 10% of the data for validation. The training is performed for 15 epochs with a batch size of 128."
      ],
      "metadata": {
        "id": "lC6Rk9iKuAq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "epochs = 15\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36tBvbCvKN9L",
        "outputId": "79117dfc-a9fb-4d8d-e5b6-44a0d5bcc15c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "422/422 [==============================] - 33s 75ms/step - loss: 0.3336 - accuracy: 0.9055 - val_loss: 0.0882 - val_accuracy: 0.9757\n",
            "Epoch 2/15\n",
            "422/422 [==============================] - 34s 80ms/step - loss: 0.0895 - accuracy: 0.9727 - val_loss: 0.0663 - val_accuracy: 0.9828\n",
            "Epoch 3/15\n",
            "422/422 [==============================] - 31s 74ms/step - loss: 0.0648 - accuracy: 0.9804 - val_loss: 0.0562 - val_accuracy: 0.9840\n",
            "Epoch 4/15\n",
            "422/422 [==============================] - 32s 77ms/step - loss: 0.0527 - accuracy: 0.9837 - val_loss: 0.0508 - val_accuracy: 0.9868\n",
            "Epoch 5/15\n",
            "422/422 [==============================] - 33s 77ms/step - loss: 0.0453 - accuracy: 0.9858 - val_loss: 0.0432 - val_accuracy: 0.9900\n",
            "Epoch 6/15\n",
            "422/422 [==============================] - 34s 80ms/step - loss: 0.0389 - accuracy: 0.9882 - val_loss: 0.0446 - val_accuracy: 0.9863\n",
            "Epoch 7/15\n",
            "422/422 [==============================] - 32s 76ms/step - loss: 0.0346 - accuracy: 0.9891 - val_loss: 0.0418 - val_accuracy: 0.9873\n",
            "Epoch 8/15\n",
            "422/422 [==============================] - 32s 76ms/step - loss: 0.0305 - accuracy: 0.9909 - val_loss: 0.0377 - val_accuracy: 0.9897\n",
            "Epoch 9/15\n",
            "422/422 [==============================] - 32s 75ms/step - loss: 0.0273 - accuracy: 0.9917 - val_loss: 0.0419 - val_accuracy: 0.9880\n",
            "Epoch 10/15\n",
            "422/422 [==============================] - 32s 77ms/step - loss: 0.0233 - accuracy: 0.9929 - val_loss: 0.0372 - val_accuracy: 0.9887\n",
            "Epoch 11/15\n",
            "422/422 [==============================] - 32s 75ms/step - loss: 0.0213 - accuracy: 0.9927 - val_loss: 0.0396 - val_accuracy: 0.9877\n",
            "Epoch 12/15\n",
            "422/422 [==============================] - 31s 75ms/step - loss: 0.0192 - accuracy: 0.9938 - val_loss: 0.0412 - val_accuracy: 0.9890\n",
            "Epoch 13/15\n",
            "422/422 [==============================] - 33s 77ms/step - loss: 0.0174 - accuracy: 0.9944 - val_loss: 0.0382 - val_accuracy: 0.9908\n",
            "Epoch 14/15\n",
            "422/422 [==============================] - 32s 75ms/step - loss: 0.0157 - accuracy: 0.9949 - val_loss: 0.0435 - val_accuracy: 0.9872\n",
            "Epoch 15/15\n",
            "422/422 [==============================] - 33s 78ms/step - loss: 0.0146 - accuracy: 0.9951 - val_loss: 0.0351 - val_accuracy: 0.9900\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f2c4aebf8b0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-Evaluate the model on the test set: The script evaluates the trained model on the test data and prints the test loss and test accuracy."
      ],
      "metadata": {
        "id": "QMfvpX9rvrVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgI2xfyJNPmm",
        "outputId": "7e3a87d3-0c87-425b-9c12-23e9c6ffce60"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.031006624922156334\n",
            "Test accuracy: 0.9908000230789185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nBAy9P9tMUsN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "changing kernel size to 5x5 and 7x7 icreases the accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "IdSFz90MDBoK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Increasing the Number of Epochs:\n",
        "\n",
        "If you increase the number of epochs, the model has more opportunities to learn from the training data.\n",
        "Initially, as you train for more epochs, you might observe that the training loss decreases, and the training accuracy improves.\n",
        "The model may start fitting the training data more closely and could potentially achieve a higher training accuracy.\n",
        "However, increasing the number of epochs significantly without any control can lead to overfitting. The model may start to memorize the training data and not generalize well to unseen data.\n",
        "\n",
        "\n",
        "Increasing the Number of Filters:\n",
        "\n",
        "Increasing the number of filters can allow the network to capture more complex and fine-grained features in the input data.\n",
        "It increases the network's capacity to learn from the data, which can be beneficial for tasks with intricate or detailed patterns.\n",
        "However, using too many filters can also increase the number of model parameters and computation, potentially leading to longer training times and an increased risk of overfitting, especially if the dataset is small."
      ],
      "metadata": {
        "id": "LKqkH6wRLr52"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7MRsM4b3vt2q"
      }
    }
  ]
}